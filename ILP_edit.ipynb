{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95656\n",
      "5020\n",
      "The size of the vocabulary is: 12102\n",
      "The possible tags are: ['DET', 'PRON', 'CONJ', 'ADP', '.', 'VERB', 'NOUN', 'ADJ', 'PRT', 'ADV', 'X', 'NUM', 'OOV']\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# download the treebank corpus from nltk\n",
    "# nltk.download('treebank')             \n",
    "# nltk.download('universal_tagset')\n",
    "\n",
    "nltk_data = list( nltk.corpus.treebank.tagged_sents( tagset ='universal') )\n",
    "train_set , test_set = train_test_split( nltk_data , train_size =0.95 , test_size =0.05 , random_state =123)\n",
    "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
    "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
    "test_words_without_tags = [ tup [0] for sent in test_set for tup in sent ]\n",
    "\n",
    "# number of tagged words in training\n",
    "print(len( train_tagged_words ) )\n",
    "print(len( test_words_without_tags ) )\n",
    "\n",
    "training_words = [ word[0] for word in train_tagged_words ]\n",
    "vocabulary = [ voc for voc in set(training_words) ]\n",
    "print(f'The size of the vocabulary is: {len(vocabulary)}')\n",
    "\n",
    "training_tags = [ word[1] for word in train_tagged_words ]\n",
    "tags = [ lab for lab in set(training_tags)]\n",
    "tags.append('OOV')      # out of vocabulary\n",
    "print(f'The possible tags are: {tags}')\n",
    "\n",
    "##\n",
    "\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)#total number of times the passed tag occurred in train_bag\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    #now calculate the total number of times the passed word occurred as the passed tag.\n",
    "    count_w_given_tag = len(w_given_tag_list) \n",
    "    return (count_w_given_tag , count_tag)\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words): \n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1]) \n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1 \n",
    "    return (count_t2_t1 , count_t1)\n",
    "\n",
    "# count how many unique tags there are in the training set\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "\n",
    "\n",
    "# make matricies\n",
    "emmision_matrix = np.zeros((len(vocabulary), len(tags)))\n",
    "for i, word in enumerate(list(vocabulary)):\n",
    "    for j, tag in enumerate(list(tags)):\n",
    "        emmision_matrix[i, j] = t2_given_t1(word, tag)[0]/t2_given_t1(word, tag)[1]\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)))\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)):\n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    "\n",
    "print(emmision_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "em_matrix = emmision_matrix\n",
    "trans_matrix = tags_matrix\n",
    "\n",
    "emission = np.zeros((len(test_words_without_tags), len(tags)))\n",
    "for row in range(len(test_words_without_tags)):\n",
    "  w = test_words_without_tags[row]\n",
    "  if w in vocabulary:\n",
    "    emission[row, :] = em_matrix[vocabulary.index(w),:]\n",
    "  else:\n",
    "    emission[row, :] = [1/len(tags) for _ in range(len(tags))]\n",
    "\n",
    "transition = trans_matrix\n",
    "n = len(test_words_without_tags)  # upperbound of sigma sum_i\n",
    "m = len(tags)                     # upperbound of sigma sum_j\n",
    "print(n,m)\n",
    "set_I  = range(0, n)\n",
    "set_J  = range(0, m)\n",
    "set_I_mod = range(1,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTRAINTS\n",
    "# <= constraints  : z_ijk =< z_ij                 for all i,j,k\n",
    "# constraints = {i,j,k : \n",
    "# m.addConstr(\n",
    "#         lhs=z[i,k]] * z[i-1,j],\n",
    "#         sense=grb.GRB.LESS_EQUAL,\n",
    "#         rhs= z[i,j], \n",
    "#         name=\"constraint_{0}\".format(i))\n",
    "#     for j in set_J for i in set_I for k in set_k}\n",
    "# >= constraints  : z_ijk => z_i-1_j + z_ik -1    for all i,j,k\n",
    "# constraints = {i,j,k : \n",
    "# m.addConstr(\n",
    "#         lhs=z[i-1, j] * z[i, k]\n",
    "#         sense=GREATER_EQUAL,\n",
    "#         rhs=z[i-1, j] + z[i, k] - 1, \n",
    "#         name=\"constraint_{0}\".format(i))\n",
    "#     for i in set_I for j in set_J for K in set_J}\n",
    "# == constraints  : sum_j z_ij = 1     for all i\n",
    "# constraints = {i : \n",
    "# m.addConstr(\n",
    "#         lhs=grb.quicksum(z[i,j] for j in set_J),\n",
    "#         sense=grb.GRB.EQUAL,\n",
    "#         rhs=1, \n",
    "#         name=\"constraint_{0}\".format(i))\n",
    "#     for i in set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cplex version\n",
    "import docplex.mp.model as cpx\n",
    "import cplex\n",
    "\n",
    "m = cpx.Model(name=\"MIP Model\")\n",
    "\n",
    "# VARIABLES\n",
    "z  = {(i,j): m.binary_var(name=\"z_{0}_{1}\".format(i,j)) \n",
    "for i in set_I for j in set_J}\n",
    "\n",
    "z3  = {(i,j,k): m.binary_var(name=\"z_{0}_{1}_{2}\".format(i,j,k)) \n",
    "for i in set_I for j in set_J for k in set_J}\n",
    "\n",
    "\n",
    "# CONSTRAINTS\n",
    "# <= constraints  : z_ijk =< z_ij                 for all i,j,k\n",
    "constraints = {(i,j,k): m.add_constraint(\n",
    "ct= z3[i,j,k] <= z[i,j],\n",
    "ctname=\"constraint_{0}_{1}_{2}\".format(i,j,k))\n",
    "       for i in set_I for j in set_J for k in set_J}\n",
    "\n",
    "# >= constraints  : z_ijk => z_i-1_j + z_ik -1    for all i,j,k\n",
    "constraints = {(i,j,k) : m.add_constraint(\n",
    "ct= z3[i,j,k] >= z[i-1,j] + z[i,k] - 1,\n",
    "ctname=\"constraint_{0}_{1}_{2}\".format(i,j,k))\n",
    "       for i in set_I_mod for j in set_J for k in set_J}\n",
    "\n",
    "# == constraints  : sum_j z_ij = 1     for all i\n",
    "constraints = {i : m.add_constraint(\n",
    "ct=m.sum(z[i,j] for j in set_J) == 1,\n",
    "ctname=\"constraint_{0}\".format(i))\n",
    "       for i in set_I}\n",
    "\n",
    "\n",
    "# OBJECTIVE       : sum_i ( sum_j (log(emission[i,j]) * z_ij) + sum_jk (log(transition[k,j]) * z_ijk)))\n",
    "sum_j = m.sum(math.log(emission[i,j]+1e-15) * z[i,j] for j in set_J for i in set_I_mod)\n",
    "sum_jk = m.sum((math.log(transition[j,k]+1e-15) * z3[i, j, k]) for j in set_J for k in set_J for i in set_I_mod)\n",
    "objective = sum_j + sum_jk\n",
    "\n",
    "\n",
    "# SOLVE\n",
    "m.maximize(objective)\n",
    "m.solve()\n",
    "\n",
    "\n",
    "# SAVE\n",
    "import pandas as pd\n",
    "opt_df = pd.DataFrame.from_dict(z, orient=\"index\", \n",
    "                                columns = [\"variable_object\"])\n",
    "opt_df.index = pd.MultiIndex.from_tuples(opt_df.index, names=[\"column_i\", \"column_j\"])\n",
    "opt_df.reset_index(inplace=True)\n",
    "opt_df[\"solution_value\"] = opt_df[\"variable_object\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
