{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the vocabulary is: 12102\n",
      "The possible tags are: ['ADV', 'DET', 'X', 'VERB', 'PRON', 'ADJ', 'NOUN', 'NUM', 'ADP', '.', 'CONJ', 'PRT', 'OOV']\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list( nltk.corpus.treebank.tagged_sents( tagset ='universal') )\n",
    "train_set , test_set = train_test_split( nltk_data , train_size =0.95 , test_size =0.05 , random_state =123)\n",
    "\n",
    "# create list of train and test tagged words\n",
    "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
    "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
    "test_words_without_tags = [ tup [0] for sent in test_set for tup in sent ]\n",
    "\n",
    "# ------------------------------------------------------------------------------------- #\n",
    "\n",
    "training_words = [ word[0] for word in train_tagged_words ]\n",
    "vocabulary = [ voc for voc in set(training_words) ]\n",
    "print(f'The size of the vocabulary is: {len(vocabulary)}')\n",
    "\n",
    "training_tags = [ word[1] for word in train_tagged_words ]\n",
    "tags = [ lab for lab in set(training_tags)]\n",
    "tags.append('OOV')      # out of vocabulary\n",
    "print(f'The possible tags are: {tags}')\n",
    "\n",
    "# initialize emission counts \n",
    "em_counts = np.zeros((len(vocabulary), len(tags)))\n",
    "  \n",
    "# iterating through the elements of list\n",
    "for i in train_tagged_words:\n",
    "  word = vocabulary.index(i[0])\n",
    "  tag = tags.index(i[1])\n",
    "  em_counts[word,tag] += 1  \n",
    "\n",
    "# get probabilities \n",
    "em_prob = np.zeros((len(vocabulary)+1, len(tags)))\n",
    "\n",
    "for row in range(0, len(em_counts)):\n",
    "  rows = em_counts[row, :]\n",
    "  em_prob[row, :] = [val/sum(rows) for val in rows]\n",
    "\n",
    "em_prob[-1, :] = [1/len(tags) for i in range(len(tags))]\n",
    "\n",
    "# create matrix\n",
    "em_matrix = np.zeros((len(vocabulary), len(tags)))\n",
    "i=0\n",
    "\n",
    "for col in range(0,12):\n",
    "  column = em_counts[:, col]\n",
    "  probs = [ val/sum(column) for val in column]\n",
    "  em_matrix[:, col] = probs\n",
    "\n",
    "# initialize transition counts\n",
    "trans_counts = np.zeros((len(tags), len(tags)))\n",
    "tag2_counts = 12 * [0]\n",
    "\n",
    "# iterating through the elements of list\n",
    "for i in range(0,len(train_tagged_words)-1):\n",
    "  curr_tag = tags.index(train_tagged_words[i][1])\n",
    "  next_tag = tags.index(train_tagged_words[i+1][1])\n",
    "  trans_counts[curr_tag, next_tag] += 1\n",
    "  tag2_counts[next_tag] += 1\n",
    "\n",
    "# calculated above as dictionary, calc in matrix\n",
    "trans_matrix = np.zeros((len(tags), len(tags)))\n",
    "i=0\n",
    "\n",
    "for col in range(0,12):\n",
    "  column = trans_counts[:, col]\n",
    "  probs = [ val/sum(column) for val in column]\n",
    "  trans_matrix[:, col] = probs\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variables:\n",
    "\n",
    "z_ij  e {0,1}   binary        label for index i is j\n",
    "\n",
    "z_ijk e {0,1}                 label for index i-1 is j and index i is k\n",
    "\n",
    "\n",
    "\n",
    "objective:\n",
    "\n",
    "sum_i ( sum_j (log(P(x_i | y_j) * z_ij) + sum_jk (log(P(y_i=k|y_i-1=j) * z_ijk)))\n",
    "\n",
    "                   emission                           transition\n",
    "\n",
    "linear in z_ij and z_ijk\n",
    "\n",
    "\n",
    "constraints:\n",
    "\n",
    "sum_j (z_ij) = 1              for all i\n",
    "\n",
    "z_ijk =< z_ij                 for all i,j,k\n",
    "\n",
    "z_ijk =< z_i-1_j + z_ik -1    for all i,j,k\n",
    "\n",
    "ILP Solver: https://realpython.com/linear-programming-python/#linear-programming-python-implementation\n",
    "https://medium.com/opex-analytics/optimization-modeling-in-python-pulp-gurobi-and-cplex-83a62129807a\n",
    "https://stackoverflow.com/questions/57025856/gurobi-constraints-and-objective-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5020 13\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "emission = np.zeros((len(test_words_without_tags), len(tags)))\n",
    "for row in range(len(test_words_without_tags)):\n",
    "  w = test_words_without_tags[row]\n",
    "  if w in vocabulary:\n",
    "    emission[row, :] = em_matrix[vocabulary.index(w),:]\n",
    "  else:\n",
    "    emission[row, :] = [1/len(tags) for _ in range(len(tags))]\n",
    "\n",
    "transition = trans_matrix\n",
    "n = len(test_words_without_tags)  # upperbound of sigma sum_i\n",
    "m = len(tags)                     # upperbound of sigma sum_j\n",
    "print(n,m)\n",
    "set_I  = range(0, n)\n",
    "set_J  = range(0, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docplex.mp.model as cpx\n",
    "import cplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "DOcplexException",
     "evalue": "Cannot solve model: no CPLEX runtime found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDOcplexException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m objective \u001b[39m=\u001b[39m sum_j \u001b[39m+\u001b[39m sum_jk\n\u001b[1;32m     49\u001b[0m m\u001b[39m.\u001b[39mmaximize(objective)\n\u001b[0;32m---> 50\u001b[0m m\u001b[39m.\u001b[39;49msolve()\n\u001b[1;32m     53\u001b[0m \u001b[39m# # optimize\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m# m.ModelSense = grb.GRB.MAXIMIZE\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# m.setObjective(objective)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# m.optimize()\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/docplex/mp/model.py:4828\u001b[0m, in \u001b[0;36mModel.solve\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4826\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_solve_local(context, used_clean_before_solve, parameter_sets)\u001b[39m# lex_timelimits, lex_mipgaps)\u001b[39;00m\n\u001b[1;32m   4827\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4828\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfatal(\u001b[39m\"\u001b[39;49m\u001b[39mCannot solve model: no CPLEX runtime found.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/docplex/mp/model.py:1078\u001b[0m, in \u001b[0;36mModel.fatal\u001b[0;34m(self, msg, *args)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfatal\u001b[39m(\u001b[39mself\u001b[39m, msg, \u001b[39m*\u001b[39margs):\n\u001b[0;32m-> 1078\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_error_handler\u001b[39m.\u001b[39;49mfatal(msg, args)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/docplex/mp/error_handler.py:210\u001b[0m, in \u001b[0;36mAbstractErrorHandler.fatal\u001b[0;34m(self, msg, args)\u001b[0m\n\u001b[1;32m    208\u001b[0m resolved_message \u001b[39m=\u001b[39m resolve_pattern(msg, args)\n\u001b[1;32m    209\u001b[0m docplex_error_stop_here()\n\u001b[0;32m--> 210\u001b[0m \u001b[39mraise\u001b[39;00m DOcplexException(resolved_message)\n",
      "\u001b[0;31mDOcplexException\u001b[0m: Cannot solve model: no CPLEX runtime found."
     ]
    }
   ],
   "source": [
    "m = cpx.Model(name=\"MIP Model\")\n",
    "\n",
    "# since z_ij is Binary\n",
    "z  = {(i,j): m.binary_var(name=\"z_{0}_{1}\".format(i,j)) \n",
    "for i in set_I for j in set_J}\n",
    "\n",
    "# IMPORTANT: z_i_jk = z_i-1_j & z_i_k = ( z[i-1, j] & z[i, k] ) = z[i-1, j] * z[i, k] \n",
    "\n",
    "# CONSTRAINTS\n",
    "# <= constraints  : z_ijk =< z_ij                 for all i,j,k\n",
    "# constraints = {i,j,k : \n",
    "# m.addConstr(\n",
    "#         lhs=z[i,k]] * z[i-1,j],\n",
    "#         sense=grb.GRB.LESS_EQUAL,\n",
    "#         rhs= z[i,j], \n",
    "#         name=\"constraint_{0}\".format(i))\n",
    "#     for j in set_J for i in set_I for k in set_k}\n",
    "# >= constraints  : z_ijk => z_i-1_j + z_ik -1    for all i,j,k\n",
    "# constraints = {i,j,k : \n",
    "# m.addConstr(\n",
    "#         lhs=z[i-1, j] * z[i, k]\n",
    "#         sense=GREATER_EQUAL,\n",
    "#         rhs=z[i-1, j] + z[i, k] - 1, \n",
    "#         name=\"constraint_{0}\".format(i))\n",
    "#     for i in set_I for j in set_J for K in set_J}\n",
    "# == constraints  : sum_j z_ij = 1     for all i\n",
    "# constraints = {i : \n",
    "# m.addConstr(\n",
    "#         lhs=grb.quicksum(z[i,j] for j in set_J),\n",
    "#         sense=grb.GRB.EQUAL,\n",
    "#         rhs=1, \n",
    "#         name=\"constraint_{0}\".format(i))\n",
    "#     for i in set_I}\n",
    "\n",
    "# == constraints\n",
    "constraints = {i : m.add_constraint(\n",
    "ct=m.sum(z[i,j] for j in set_J) == 1,\n",
    "ctname=\"constraint_{0}\".format(i))\n",
    "       for i in set_I}\n",
    "\n",
    "\n",
    "\n",
    "set_I_mod = range(1,n)\n",
    "# objective       : sum_i ( sum_j (log(emission[i,j]) * z_ij) + sum_jk (log(transition[k,j]) * z_ijk)))\n",
    "sum_j = m.sum(math.log(emission[i,j]+1e-15) * z[i,j] for j in set_J for i in set_I_mod)\n",
    "sum_jk = m.sum((math.log(transition[j,k]+1e-15) * (z[i, k] * z[i-1, j])) for j in set_J for k in set_J for i in set_I_mod)\n",
    "objective = sum_j + sum_jk\n",
    "\n",
    "m.maximize(objective)\n",
    "m.solve()\n",
    "\n",
    "\n",
    "# # optimize\n",
    "# m.ModelSense = grb.GRB.MAXIMIZE\n",
    "# m.setObjective(objective)\n",
    "# m.optimize()\n",
    "\n",
    "import pandas as pd\n",
    "opt_df = pd.DataFrame.from_dict(z, orient=\"index\", \n",
    "                                columns = [\"variable_object\"])\n",
    "opt_df.index = pd.MultiIndex.from_tuples(opt_df.index, names=[\"column_i\", \"column_j\"])\n",
    "opt_df.reset_index(inplace=True)\n",
    "opt_df[\"solution_value\"] = opt_df[\"variable_object\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
